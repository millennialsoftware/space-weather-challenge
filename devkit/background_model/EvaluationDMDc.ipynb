{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15YXsBIWY_Wh",
   "metadata": {},
   "source": [
    "# Install & import libraries 📚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "UEEuRw7Cxuuy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os              : Linux-5.10.221-llgrid-x86_64-with-glibc2.35\n",
      "python          : 3.9.16\n",
      "tsai            : 0.3.6\n",
      "fastai          : 2.7.12\n",
      "fastcore        : 1.5.29\n",
      "sklearn         : 1.2.2\n",
      "torch           : 2.0.1+cu117\n",
      "device          : 2 gpus (['Tesla V100-PCIE-32GB', 'Tesla V100-PCIE-32GB'])\n",
      "cpu cores       : 40\n",
      "threads per cpu : 2\n",
      "RAM             : 377.57 GB\n",
      "GPU memory      : [32.0, 32.0] GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 13:06:37.590010: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-04 13:06:37.708891: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-04 13:06:38.388194: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-04 13:06:38.388253: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-04 13:06:38.388258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from tsai.basics import *\n",
    "my_setup(sklearn)\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time\n",
    "import pandas as pd\n",
    "import mat73\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.linalg import pinv\n",
    "from scipy.linalg import logm\n",
    "import pandas as pd\n",
    "\n",
    "from tsai.optuna import *\n",
    "import papermill as pm\n",
    "from tsai.optuna import run_optuna_study\n",
    "from fastcore.basics import *\n",
    "from torch.cuda import amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c95c7b0-62de-48da-ac06-0a5b3299a24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Check for GPUs\n",
    "# Change the CUDA_VISIBLE_DEVICES values to numbers\n",
    "# See (https://forums.fast.ai/t/exception-occured-in-lrfinder-when-calling-event-after-fit/104389/8)\n",
    "if torch.cuda.is_available():\n",
    "    result = subprocess.check_output(\"nvidia-smi -L | grep -oE '[0-9]+:' | tr -d ':'\", shell=True).decode(\"utf-8\").strip()\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = result\n",
    "\n",
    "    print(os.environ['CUDA_VISIBLE_DEVICES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a620ad3-3a50-46d8-8874-8ecc2adf180b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61721f2d-a8fb-485b-a98b-c77897e1e095",
   "metadata": {},
   "source": [
    "# Model and Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77af3910-4600-4544-be79-7e573ad8bc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a data set:\n",
      "1. NRLMSISE\n",
      "2. TIEGCM\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of your choice:  1\n"
     ]
    }
   ],
   "source": [
    "# Define the available options\n",
    "data_options = [\"NRLMSISE\", \"TIEGCM\"]\n",
    "\n",
    "# Ask the user to select a data set\n",
    "print(\"Please select a data set:\")\n",
    "for i, option in enumerate(data_options, 1):\n",
    "    print(f\"{i}. {option}\")\n",
    "data_choice = int(input(\"Enter the number of your choice: \"))\n",
    "data_name = data_options[data_choice - 1]\n",
    "\n",
    "# Use the data_name in your naming path\n",
    "path = f\"data/{data_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7658e2b0-4e10-44b8-957d-a2ff264df45c",
   "metadata": {},
   "source": [
    "#### Choose Training, Validation, and Test Density Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f68a7d15-e55c-4347-adcd-0b08b978f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NRLMSISE\n",
    "if data_name == 'NRLMSISE':\n",
    "    df_raw = loadmat('../Nikki_DESTO.jl/DESTO.jl/ROM/NRLMSISE_1997_2008_ROM_r100.mat')\n",
    "\n",
    "# TIEGCM\n",
    "if data_name == 'TIEGCM':\n",
    "    df_raw = scipy.io.loadmat('../Nikki_DESTO.jl/DESTO.jl/ROM/TIEGCM_1997_2008_ROM_r100.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2be20c-04f6-421a-a18f-2c8dc5edbf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POD Dimension\n",
    "r=10\n",
    "\n",
    "# Atmospheric Density Snapshots\n",
    "X = df_raw[\"densityDataLogVarROM100\"][:r,:];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6663625f-6358-45d1-b182-18776db32367",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dee32de-6072-4e2d-93ab-d97d0279e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "freq = '1H'\n",
    "\n",
    "fcst_history = 24*3*6 # 1/freq*18 (18 days) 432 steps in the past\n",
    "fcst_horizon = 24*3  # 1/freq*3 (3 days) 72 steps in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4523888-9997-4975-9811-b3ffeff14817",
   "metadata": {},
   "source": [
    "#### Load Dataset and Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4fb4cf4-4c8d-4f50-b0ad-fa138ac34c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 1) Processing scaler, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 1) Processing scaler, total=   0.1s\n",
      "[Pipeline] ............ (step 1 of 1) Processing scaler, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "# Load dataframes\n",
    "low_df = load_object('training/training_data/low_df_'+path+'.pkl')\n",
    "low_df = low_df.reset_index(drop=True)\n",
    "\n",
    "medium_df = load_object('training/training_data/medium_df_'+path+'.pkl')\n",
    "medium_df = medium_df.reset_index(drop=True)\n",
    "\n",
    "high_df = load_object('training/training_data/high_df_'+path+'.pkl')\n",
    "high_df = high_df.reset_index(drop=True)\n",
    "\n",
    "# Load splits\n",
    "low_splits = load_object('training/splits/splits_lowSW_'+path+'.pkl')\n",
    "medium_splits = load_object('training/splits/splits_mediumSW_'+path+'.pkl')\n",
    "high_splits = load_object('training/splits/splits_highSW_'+path+'.pkl')\n",
    "\n",
    "# Low SW\n",
    "train_split = low_splits[0]\n",
    "exp_pipe = load_object('training/exp_pipe/exp_pipe_lowSW_'+path+'.pkl')\n",
    "low_df_scaled = exp_pipe.fit_transform(low_df, scaler__idxs=train_split)\n",
    "\n",
    "# Medium SW\n",
    "train_split = medium_splits[0]\n",
    "exp_pipe = load_object('training/exp_pipe/exp_pipe_mediumSW_'+path+'.pkl')\n",
    "medium_df_scaled = exp_pipe.fit_transform(medium_df, scaler__idxs=train_split)\n",
    "\n",
    "# High SW\n",
    "train_split = high_splits[0]\n",
    "exp_pipe = load_object('training/exp_pipe/exp_pipe_highSW_'+path+'.pkl')\n",
    "high_df_scaled = exp_pipe.fit_transform(high_df, scaler__idxs=train_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8aab2e-b74f-4f31-bad8-6c91915d54e5",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f8e769f-b065-4502-a5f1-382b2eb22e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a data set:\n",
      "1. low space weather\n",
      "2. medium space weather\n",
      "3. high space weather\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of your choice:  3\n"
     ]
    }
   ],
   "source": [
    "# Define the available options\n",
    "data_options = [\"low space weather\", \"medium space weather\", \"high space weather\"]\n",
    "\n",
    "# Ask the user to select a data set\n",
    "print(\"Please select a data set:\")\n",
    "for i, option in enumerate(data_options, 1):\n",
    "    print(f\"{i}. {option}\")\n",
    "data_choice = int(input(\"Enter the number of your choice: \"))\n",
    "training_name = data_options[data_choice - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7ac7d00-fbb1-4722-a394-209d92cd6b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 1) Processing scaler, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "if training_name == 'low space weather':\n",
    "    # Low SW\n",
    "    columns = low_df.columns[1:]\n",
    "    train_split = low_splits[2]\n",
    "    exp_pipe = load_object('training/exp_pipe/exp_pipe_lowSW_'+path+'.pkl')\n",
    "    combined_df_test =  np.array(exp_pipe.fit_transform(low_df, scaler__idxs=train_split))\n",
    "elif training_name == 'medium space weather':\n",
    "    # Medium SW\n",
    "    columns = medium_df.columns[1:]\n",
    "    train_split = medium_splits[2]\n",
    "    exp_pipe = load_object('training/exp_pipe/exp_pipe_mediumSW_'+path+'.pkl')\n",
    "    combined_df_test =  np.array(exp_pipe.fit_transform(medium_df, scaler__idxs=train_split))\n",
    "elif training_name == 'high space weather':\n",
    "    # High SW\n",
    "    columns = high_df.columns[1:]\n",
    "    train_split = high_splits[2]\n",
    "    exp_pipe = load_object('training/exp_pipe/exp_pipe_highSW_'+path+'.pkl')\n",
    "    combined_df_test =  np.array(exp_pipe.fit_transform(high_df, scaler__idxs=train_split))\n",
    "else:\n",
    "    print(\"Name not recognized\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab79fef-db05-40e0-8493-dbdfbee46691",
   "metadata": {},
   "source": [
    "# Evaluate model 🕵️‍♀️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3b23bf6-4764-4c8b-b791-27e24c25853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "U1 = combined_df_test[:-1,11:]\n",
    "\n",
    "X1 = combined_df_test[:-1,1:]\n",
    "X2 = combined_df_test[1:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb339f4e-7425-4fa0-b2b7-a10e4d363d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2 = A*X1 + B*U1 = [A B]*[X1;U1] = Phi*Om\n",
    "Om = X1\n",
    "Om_numeric = Om.T.astype(np.float64)\n",
    "\n",
    "# Phi = X2*pinv(Om)\n",
    "Phi = np.dot(X2.T, np.linalg.pinv(Om_numeric))\n",
    "\n",
    "# Revert to just density\n",
    "X1 = combined_df_test[:-1, 1:r+1]\n",
    "X2 = combined_df_test[1:, 1:r+1]\n",
    "\n",
    "# Discrete-time dynamic and input matrix\n",
    "q = np.size(U1,1);\n",
    "\n",
    "A = Phi[:r, :r]\n",
    "B = Phi[:r, r:]\n",
    "\n",
    "dth = round(1/float(freq[:-1]))    # discrete time dt of the ROM in hours\n",
    "AB = np.concatenate((A, B), axis=1)\n",
    "zeros_eye = np.concatenate((np.zeros((q, r)), np.eye(q)), axis=1)\n",
    "\n",
    "Phi = np.concatenate((AB, zeros_eye), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "617b454e-3271-4ea0-86aa-189fd62d81c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Covariance\n",
    "X2Pred = []\n",
    "errPred = []\n",
    "Qrom = []\n",
    "mse = []\n",
    "mae = []\n",
    "\n",
    "X2Pred.append(np.dot(A, X1[0].T) + np.dot(B, U1[0].T))  # Predict ROM state for 1hr\n",
    "errPred.append(X2Pred[0] - X2[0].T)  # Error of prediction w.r.t. training data\n",
    "# Calculate MSE\n",
    "mse.append(mean_squared_error(X2[0].T, X2Pred[0]))\n",
    "# Calculate MAE\n",
    "mae.append(mean_absolute_error(X2[0].T, X2Pred[0]))\n",
    "Qrom.append(np.cov(errPred[0].astype(float)))  # Covariance of error\n",
    "idx = [0]\n",
    "\n",
    "for i in range(fcst_horizon):\n",
    "    X2Pred.append(np.dot(A, X2Pred[i].T) + np.dot(B, U1[i].T))  # Predict ROM state for 1hr\n",
    "    errPred.append(X2Pred[i+1] - X2[i+1].T)  # Error of prediction w.r.t. training data\n",
    "    # Calculate MSE\n",
    "    mse.append(mean_squared_error(X2[i+1].T, X2Pred[i+1]))\n",
    "    # Calculate MAE\n",
    "    mae.append(mean_absolute_error(X2[i+1].T, X2Pred[i+1]))\n",
    "    Qrom.append(np.cov(errPred[i+1].astype(float)))  # Covariance of error\n",
    "    idx.append(i+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
